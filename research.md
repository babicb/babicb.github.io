---
layout: page
title: Research
---
<!--- You will find below a list of publications and works in progress, followed by a general overview of my research. --> 

You can find my Google Scholar profile [here](https://scholar.google.com/citations?user=4qmPIBgAAAAJ&hl=en&oi=ao).

**Academic Articles**

1. The Algorithmic Explainability Bait and Switch,   
**Minnesota Law Review** (2023)    
with I. Glenn Cohen [PDF](research/explainability_march2023.pdf)
2. Algorithmic Fairness and Resentment,   
**Philosophical Studies** (2023)    
with Zoe Johnson King [PDF](research/afr.pdf)
3. Appealing AI,      
**Nature Digital Medicine** (2023)    
with I. Glenn Cohen, Sara Gerke, Qiong Xia,   
Theodoros Evgeniou and Klaus Werternbroch [PDF](research/AppealingAI.pdf)    
5. Moral Encroachment Under Moral Uncertainty,   
**Philosophers' Imprint** (2023)    
with Zoe Johnson King [PDF](research/encroachment_march2023.pdf)       
6. Comment on Ariel Dora Stern's Regulation of Medical AI,   
**The Economics of Artificial Intelligence**    
edited by Ajay Agrawal, Joshua Gans, and Avi Goldfarb (2023) [PDF](research/ads_comment_march2023.pdf)           
7. Beware Explanations from AI in Health Care,      
**Science** (2021)    
with I. Glenn Cohen, Theodoros Evgeniou and Sara Gerke [PDF](research/beware_march2023.pdf), [link](https://www.science.org/doi/10.1126/science.abg1834)  
&nbsp;&nbsp;&nbsp;&nbsp; Media Coverage:   
&nbsp;&nbsp;&nbsp;&nbsp; [Forbes](https://www.forbes.com/sites/forbestechcouncil/2021/08/23/10-key-questions-every-company-should-ask-before-using-ai/?sh=6070c2415d62), [Proto (Time Magazine/MGH)](http://protomag.com/research-studies/ai-explain-thyself/),   
&nbsp;&nbsp;&nbsp;&nbsp; [Tencent QQ](https://new.qq.com/omn/20210903/20210903A0C0DC00.html), [The Edge](https://www.theedgemarkets.com/article/ai-are-we-ready-black-box-solutions),   
&nbsp;&nbsp;&nbsp;&nbsp; [China Business News](https://www.yicai.com/news/101163033.html)
8. Direct to Consumer Advertising of Medical Machine Learning,      
**Nature Machine Intelligence** (2021)    
with I. Glenn Cohen, Theodoros Evgeniou and Sara Gerke [PDF](research/dtc_march2023.pdf), [link](https://www.nature.com/articles/s42256-021-00331-0)     
9. Normativity, Epistemic Rationality and Noisy Statistical Evidence,       
**The British Journal for the Philosophy of Science** (2021)       
with Anil Gaba, Ilia Tsetlin, and Robert L. Winkler [PDF](research/noisy_stereotypes_march2021.pdf), [link](https://www.journals.uchicago.edu/doi/10.1086/715196)    
10. Approximate Coherentism and Luck,     
**Philosophy of Science** (2021) [PDF](research/acl.pdf), [link](https://www.cambridge.org/core/journals/philosophy-of-science/article/abs/approximate-coherentism-and-luck/362F44FD87EEA07E0E60EF57CD34768D) 
11. A System View for Medical ML Policy,      
**Nature Digital Medicine** (2020)     
with I. Glenn Cohen, Theodoros Evgeniou and Sara Gerke [PDF](research/nature_system_view.pdf), [link](https://www.nature.com/articles/s41746-020-0262-2)   
&nbsp;&nbsp;&nbsp;&nbsp; Media Coverage: [STAT News](https://www.statnews.com/2020/10/05/duke-artificial-intelligence-hospital-medicine/)
12. Algorithms on Regulatory Lockdown,      
**Science** (2019)    
with I. Glenn Cohen, Theodoros Evgeniou and Sara Gerke  [PDF](locked_ai_nov2019.pdf), [link](https://www.science.org/doi/abs/10.1126/science.aay9547)    
&nbsp;&nbsp;&nbsp;&nbsp; Media Coverage: [Forbes](https://www.forbes.com/sites/lanceeliot/2019/12/18/latest-ai-that-learns-on-the-fly-is-raising-serious-concerns-including-for-self-driving-cars/#7ea94f162813)   
13. Moral Obligation & Epistemic Risk,        
**Oxford Studies in Normative Ethics** (2020)    
with Zoe Johnson King [PDF](research/bjk_mer_2019.pdf), [link](https://oxford.universitypressscholarship.com/view/10.1093/oso/9780198867944.001.0001/oso-9780198867944-chapter-5)    
14. A Theory of Epistemic Risk,     
**Philosophy of Science** (2019) [PDF](research/babic_ter_final.pdf), [link](https://doi.org/10.1086/703552)    
  
**Other Writing**   
<ol start="14">
    <li> Explaining Medical AI is Easier Said than Done, <b>STAT News</b> (2020) <a href="https://www.statnews.com/2021/07/21/explainable-medical-ai-easier-said-than-done/">link</a> <br>  
with Sara Gerke </li>
    <li> When Machine Learning Goes off the Rails, <b>Harvard Business Review</b> (2020) <a href="https://hbr.org/2021/01/when-machine-learning-goes-off-the-rails">link</a> <br>  
with I. Glenn Cohen, Theodoros Evgeniou, and Sara Gerke </li>
  <li> Can AI Decide Who Gets an Organ Transplant?, <b>Harvard Business Review</b> (2020) <a href="https://hbr.org/2020/12/can-ai-fairly-decide-who-gets-an-organ-transplant">link</a> <br>  
with I. Glenn Cohen, Theodoros Evgeniou, Sara Gerke, and Nikos Trichakis </li>
  <li> A Better Way to Onboard AI, <b>Harvard Business Review</b> (2020) <a href="https://hbr.org/2020/07/a-better-way-to-onboard-ai">link</a> <br>   
with Daniel Chen, Theodoros Evgeniou, and Anne-Laure Fayard </li> 
</ol>

**Work in Progress** 

<ol start="18">
  <li> Resolute and Correlated Bayesians (under review) </li>
  <li> Reframing the Accuracy-Interpretability Tradeoff (under review) </li>
</ol> 

&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;
&nbsp;

<!---
<ol start="3">
  <li>A paper on approximate coherence </li>
  <li>Norms, Stereotypes and Accuracy <a href="babic_nsa.pdf">PDF</a> </li>
  <li>Adaptive Burdens of Proof (e-mail for draft) </li>
  <li>Dynamic Epistemic Risk </li>
  <li>Testing for Discrimination and the Risk of Error </li>
  <li>Invariance, Entropy, and (Objective) Bayesianism </li>
</ol> 
<!---
**Overview**
  The overaching theme of my current research is **epistemic risk**. It consists of three principal components:
**Philosophy of science/formal epistemology**. I try to motivate and construct a general theory of epistemic risk in terms of alethic sensitivity to small changes in accuracy. This theory is currently developed within the epistemic utility framework, though I think of this as a starting point rather than a fundamental commitment. If you would like to learn more, see the paper entitled A Theory of Epistemic Risk. This project proposes a way of measuring the riskiness of a credence function and connects risk to measures of uncertainty. In particular, I show that under very general conditions epistemic risk is dual to information entropy. 
Currently, I am working on a project that extends considerations of epistemic risk to the updating of beliefs (Dynamic Epistemic Risk). I aim to show that we can establish an update rule by considering how an agent's attitudes to epistemic risk should change in response to different possible learning experiences. Roughly, if the answer is that attitudes to epistemic risk should change as little as possible, then the associated update rule is Bayes' Rule. 
I am also working on a project on chance and coherence for imperfect Bayesian agents (Assessment Reversal in Approximate Coherentism). I suggest that approximating coherence may not be an appropriate proxy for traditional (all or nothing) coherence because unlike the latter, approximating coherence is susceptible to misfortune. 
**Normative ethics**. I believe the theory of epistemic risk can fruitfully speak to several problems that have been articulated in the moral encroachment and normative dilemmas literature. In a joint project with ZoÃ« Johnson-King (Moral Obligations and Epistemic Risk), we explore the relationship between moral obligations and attitudes to epistemic risk.
**Law and public policy**. This dimension of my research engages the emerging literature on algorithmic fairness and ethics in statistics and machine learning. I am interested in both the normative dimension of what constitutes fair AI/ML and the statistical engineering problem of how to construct fair learning algorithms. I am also interested in the empirical study of related public policy problems. Currently, I am working on applying the theory of epistemic risk to evaluate the pervasiveness of discrimination. In particular, in Testing for Discrimination and the Risk of Error, I defend a statistical test for discrimination grounded in attitudes to epistemic risk. Meanwhile, in Adaptive Burdens of Proof, I argue that many apparent paradoxes of proof involving statistical evidence arise because we assume (without justification) that legal decision makers must have one unique attitude to epistemic risk -- namely, neutrality.  -->
